{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c1e48e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ....\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jesus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.vocabulary import Vocabulary\n",
    "from nltk import download\n",
    "import glob\n",
    "import itertools\n",
    "import email\n",
    "import string\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.data import load\n",
    "download('punkt', download_dir='.')\n",
    "download('stopwords')\n",
    "\n",
    "# Función para leer los emails de un directorio dado\n",
    "\n",
    "def readEmails(url):\n",
    "    url = str(url)\n",
    "    mails = []\n",
    "    i = 0\n",
    "    for s in glob.glob(url+\"*\"):\n",
    "        with open(url+s.split(\"\\\\\")[1]) as file_:\n",
    "            mail = email.message_from_file(file_)\n",
    "            mails.append(mail.get(\"Subject\"))\n",
    "        if i >=50:\n",
    "            break\n",
    "        i=i+1\n",
    "    return mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dae6afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para eliminar los signos de puntuación de un texto dado\n",
    "\n",
    "def cleanText(text):\n",
    "    punctuations = []\n",
    "    words = []\n",
    "    for c in text:\n",
    "        if c not in string.punctuation:\n",
    "            \n",
    "            punctuations.append(c)\n",
    "    punctuations = ''.join(punctuations)\n",
    "    \n",
    "    for t in punctuations.split():\n",
    "        if t.lower() not in stopwords.words('english'):\n",
    "           \n",
    "            words.append(t.lower())\n",
    "    words = ' '.join(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d0acabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order cheap vallum ship worldwide', 'sper pass anyone taking medications', '', 'server mailing', 'phamacy online dragnet', '', 'meet 3 million eligible singles area', 'dont know attract customers website', 'progress aujy dep', 'search optimization', 'yasheng group yhgg announces 1st quarter results 145 million revenue', 'returned mail see transcript details', 'infected read details', 'continued growth orbit drop inc acquisitions changes take place positioning obdp next level', 'enjoy media ejym enters chinese tv advertising market', 'new penis enlargement patches', 'get orders anything sell millions customers sent website', 'home depot gift card waiting', 'graphics software available cheap oem versions', 'finally possible enlarge penis', 'question website', '', 'top placement', 'dont know get search engine results', 'joint business alliance', 'professional advertising', 'save money getting oem software', 'lottery winning notifications', 'update account information', 'hotshot stock report', 'microcap communiquð¹', 'financial marketing skills seminar', '5000 full color postcards 329', 'wearable electronics', 'perfect logo identity key success', 'visual identity logo', 'graphics software available cheap oem versions', '5000 full color postcards 329', 'listed major search engines', 'hi', 'please dont ignoreread carefully conformation code cng dqag', 'interesting', 'windows1252qcomoayudaranif1osmexicanosdesamparados', 'julie invites free webcam', 'suprise woman', 'account suspended', 'loretta emory', 'biblioteca henestrosa', '1000 full color brochures 335', 'iso88591bt2zmawnlihnvznr3yxjlic0gzhv0es1mcmvlihbyawnlcw', 'double reading speed 2 weeks']\n"
     ]
    }
   ],
   "source": [
    "subjects = readEmails(\"Enron-Spam/no_deseado/\")\n",
    "clean_subjects = [cleanText(s) for s in subjects]\n",
    "print(clean_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3933c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b3831d6",
   "metadata": {},
   "source": [
    "Dividimos el conjunto de mensajes proporcionado en dos subconjuntos, uno de entrenamiento (con el 80% de los correos del conjunto incial) y el otro de validación (con el 20% de correos restantes), usando la bibioteca splitfolders de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa546ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 25404 files [01:53, 224.22 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio(\"Enron-Spam\", output=\"Enron-Spam-Splited\", seed=1337, ratio=(.8, .2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0590bcdd",
   "metadata": {},
   "source": [
    "Para representar de forma numérica el contenido de los correos electrónicos usamos como modelo de lenguaje el conocido como bolsa de palabras\n",
    "Bibliografía: https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5046f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d065c",
   "metadata": {},
   "source": [
    "Tokenizamos las palabras que encontramos en los correos y contamos las ocurrencias de cada una, y las representamos en una matriz en la que las filas se correponden con los distintos correos, mientras que las columnas son las distintas palabras que conforman el vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2b7f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(clean_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef363623",
   "metadata": {},
   "source": [
    "Mostramos las 50 primeras palabras del vocabulario, que se correponden con las 50 primeras columnas de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "673ef334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1000' '145' '1st' '329' '335' '5000' 'account' 'acquisitions'\n",
      " 'advertising' 'alliance' 'announces' 'anyone' 'anything' 'area' 'attract'\n",
      " 'aujy' 'available' 'biblioteca' 'brochures' 'business' 'card' 'carefully'\n",
      " 'changes' 'cheap' 'chinese' 'cng' 'code' 'color' 'communiquð¹'\n",
      " 'conformation' 'continued' 'customers' 'dep' 'depot' 'details' 'dont'\n",
      " 'double' 'dqag' 'dragnet' 'drop' 'ejym' 'electronics' 'eligible' 'emory'\n",
      " 'engine' 'engines' 'enjoy' 'enlarge' 'enlargement' 'enters']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out()[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524e5d4",
   "metadata": {},
   "source": [
    "Mostramos las filas y columnas de la matriz en forma de array. Cada elemento representa el número de veces que aparece la palabra de la columna en el correo de la fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5c46cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44a811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
